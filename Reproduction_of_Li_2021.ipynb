{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee0f51a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Collecting regex>=2021.8.3\n",
      "  Using cached regex-2022.4.24-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (763 kB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk) (4.64.0)\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.7 regex-2022.4.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Using cached lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.9/site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from lightgbm) (1.8.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from lightgbm) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /opt/conda/lib/python3.9/site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.2\n",
      "Collecting fasttext\n",
      "  Using cached fasttext-0.9.2-cp39-cp39-linux_x86_64.whl\n",
      "Collecting pybind11>=2.2\n",
      "  Using cached pybind11-2.9.2-py2.py3-none-any.whl (213 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from fasttext) (1.21.6)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from fasttext) (62.1.0)\n",
      "Installing collected packages: pybind11, fasttext\n",
      "Successfully installed fasttext-0.9.2 pybind11-2.9.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Installations and imports\n",
    "import pandas\n",
    "!pip install nltk\n",
    "import nltk\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# data_path = Path(\"/mnt/f/workspace/DataCLUE/nips_expr/aclImdb\")\n",
    "data_path = Path(\"/home/jovyan/Data Mining Grad Project/ACL_IMDB\")\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopWords = stopwords.words('english')\n",
    "\n",
    "#install other important things\n",
    "!pip install lightgbm\n",
    "!pip install fasttext\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# stopwords = set(Path(\"/mnt/f/workspace/DataCLUE/nips_expr/stopwords.txt\").read_text().split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd3fdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 24468.14it/s]\n",
      "12500it [00:09, 1379.11it/s]\n",
      "12500it [00:09, 1359.04it/s]\n",
      "12500it [00:09, 1359.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def load_data(path):\n",
    "    labels = []\n",
    "    texts = []\n",
    "    for file_path in tqdm((path / \"neg\").glob(\"*.txt\")):\n",
    "        labels.append(0)\n",
    "        texts.append(file_path.read_text())\n",
    "    \n",
    "    for file_path in tqdm((path / \"pos\").glob(\"*.txt\")):\n",
    "        labels.append(1)\n",
    "        texts.append(file_path.read_text())\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "all_train_texts, train_Y = load_data(data_path / \"train\")\n",
    "all_test_texts, test_Y = load_data(data_path / \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d519961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def data_quality(vectorizer, X, train_Y, cut_prop=1, filter_set = set()):\n",
    "    from sklearn.feature_selection import f_classif, chi2\n",
    "    F, pvalues_f = chi2(X, train_Y)\n",
    "    \n",
    "    last = int(len(F) * cut_prop)\n",
    "    sorted_F = sorted(zip(vectorizer.get_feature_names(), F), key=lambda x: x[1], reverse=True)[:last]\n",
    "    \n",
    "    values = [value for name, value in sorted_F if name not in filter_set]\n",
    "    # max_value, min_value = max(values), min(values)\n",
    "\n",
    "\n",
    "\n",
    "    # values = [(value - min_value) / (max_value - min_value) for value in values]\n",
    "\n",
    "    # print(values[:10])\n",
    "    # print(values[-10:])\n",
    "\n",
    "    return sum(values) / len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0971d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_classifier(train_x, train_y, test_x):  \n",
    "    from sklearn.naive_bayes import MultinomialNB  \n",
    "    model = MultinomialNB(alpha=0.01)  \n",
    "    model.fit(train_x, train_y)\n",
    "    return model.predict(test_x)\n",
    "\n",
    "def svm_classifier(train_x, train_y, test_x):\n",
    "    from sklearn.svm import SVC  \n",
    "    model = SVC(kernel='rbf', probability=True, max_iter=50)\n",
    "    model.fit(train_x, train_y)\n",
    "    return model.predict(test_x)\n",
    "\n",
    "def lgb_classifier(train_x, train_y, test_x):\n",
    "    import lightgbm as lgb\n",
    "    import numpy as np\n",
    "    \n",
    "    train_data = lgb.Dataset(train_x.astype('float32'), label=np.array(train_y, np.float32))\n",
    "#     test_data = lgb.Dataset(test_x, label=test_y)\n",
    "    \n",
    "    params={\n",
    "#         'learning_rate':0.1,\n",
    "#         'lambda_l1':0.1,\n",
    "#         'lambda_l2':0.2,\n",
    "#         'max_depth':6,\n",
    "#         'min_data_'\n",
    "        'objective':'multiclass',\n",
    "        'num_iteration': 200, \n",
    "        'num_class': 2,\n",
    "    }\n",
    "    \n",
    "    model = lgb.train(params, train_data)\n",
    "    return np.argmax(model.predict(test_x.astype('float32')), axis=1)\n",
    "\n",
    "def fasttext_classifier(train_texts, train_y, test_texts, test_y, name):\n",
    "    import fasttext\n",
    "\n",
    "    model_path = data_path / f\"fasttext.model.{name}.bin\"\n",
    "    if model_path.exists():\n",
    "        classifier = fasttext.load_model(str(model_path))\n",
    "    else:\n",
    "        write_path = data_path / f\"fasttext.data.train.{name}.txt\"\n",
    "        write_path.write_text(\"\\n\".join(\n",
    "            f\"{sentence}\\t__label__{label}\" for sentence, label in zip(train_texts, train_Y)\n",
    "        ))\n",
    "\n",
    "        classifier = fasttext.train_supervised(str(write_path), lr=0.1, word_ngrams=3, bucket=2000000, label_prefix=\"__label__\")\n",
    "        classifier.save_model(str(model_path))\n",
    "        \n",
    "    labels, _ = classifier.predict(test_texts)\n",
    "    y_pred = [int(label[0][-1]) for label in labels]\n",
    "    return y_pred\n",
    "\n",
    "def knn_classifier(train_X, train_Y, test_X):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    model = KNeighborsClassifier(n_neighbors=3)  \n",
    "    model.fit(train_X, train_Y)\n",
    "    return [4]\n",
    "    return model.predict(test_X)\n",
    "\n",
    "def textcnn(train_x, train_y):\n",
    "    from deepclassifier.models import TextCNN\n",
    "    from deepclassifier.trainers import Trainer\n",
    "    import torch.optim as optim\n",
    "    \n",
    "    model = TextCNN(embedding_dim=300, dropout_rate=0.2, num_class=2)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "772ee804",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mapper = {\n",
    "    \"nb\": naive_bayes_classifier,\n",
    "    \"svm\": svm_classifier,\n",
    "    \"lgb\": lgb_classifier,\n",
    "    \"knn\": knn_classifier,\n",
    "    \"fasttext\": None,\n",
    "    \"textcnn\": None,\n",
    "}\n",
    "\n",
    "def train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, model_name):\n",
    "    if model_name not in model_mapper:\n",
    "        y_pred = fasttext_classifier(train_texts, train_Y, test_texts, test_Y, model_name)\n",
    "    else:\n",
    "        y_pred = model_mapper[model_name](train_X, train_Y, test_X)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    return accuracy_score(test_Y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4aa5e",
   "metadata": {},
   "source": [
    "# No Operations_Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c71d25ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(lowercase=False)\n",
    "train_X = vectorizer.fit_transform(all_train_texts)\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import f_classif, chi2\n",
    "F, pvalues_f = chi2(train_X, train_Y)\n",
    "\n",
    "sorted_F = sorted(zip(vectorizer.get_feature_names(), F), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a1a169f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and rent a GOOD horror movie. It\\'s like the writer had never seen a horror movie before and didn\\'t realize every single thing he wrote was clichéd and hackneyed and has been parodied to perfection in movies like \"Scream\" and \"Scary Movie\".<br /><br />In between the scary bits is the most BANAL and BORING dialog ever written. Stupid \"we\\'re going to the prom\" junk. I wanted to claw my ears off. Honestly, \"The Hills\" has better dialog.<br /><br />There really was no need to make this movie. Leading lady is uninteresting and I kept thinking \"Her? Really? Guy is obsessed with her? Really?\" <br /><br />All the characters act in stupid ways, including the police. (Cover the place in teams of 2! Front and back! Not one sleepy cop sitting in his car with the window rolled down just waiting for his throat to be slashed.) <br /><br />The serial killer just swans about murdering everyone he wants without the least bit of problem. No resistance from victims (or doors). Nobody has any protection or the least idea of fighting back (or flipping the security lock on the hotel room door). The people are like mentally disabled sheep.<br /><br />By the by, if you\\'re a gore fan, you\\'ll be disappointed too. All the killing is kept offscreen and is -- ahem -- tastefully done. (So boo hoo for you!) <br /><br />None of the killings is the least bit interesting. Most of the time they\\'ve already happened by the time we find out.<br /><br />The only cliché missing was the cat that always pops out in this kind of movies. \"Oh kitty! You scared me! I thought you were the killer -- AIIEEEE!\" <br /><br />And then at the end when it\\'s time for the killer to die -- well, let\\'s just say it\\'s the easiest and most obvious choice. Snore.<br /><br />The audience was jeering and talking back to the screen throughout. It was too dumb to believe and not really scary enough. Don\\'t encourage this kind of lazy film-making.<br /><br />(Oh, and by the way -- no crowning of a prom king or queen. No tiara. No bucket of blood.) <br /><br />So save your money and rent \"Carrie\" or \"Friday the 13th\" or \"Halloween\" or \"Scream\" or \"Scary Movie\" (any of them) to get a good scare with some original twists.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55b671d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7865934961112424"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=False)\n",
    "train_X = vectorizer.fit_transform(all_train_texts)\n",
    "test_X = vectorizer.transform(all_test_texts)\n",
    "\n",
    "data_quality(vectorizer, train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "685f889e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62976"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(all_train_texts, train_X, train_Y, all_test_texts, test_X, test_Y, \"nb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe5e1617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51788"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(all_train_texts, train_X, train_Y, all_test_texts, test_X, test_Y, \"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46ba5388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 3.627349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 33533\n",
      "[LightGBM] [Info] Number of data points in the train set: 13500, number of used features: 8978\n",
      "[LightGBM] [Info] Start training from score -2.602690\n",
      "[LightGBM] [Info] Start training from score -0.076961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.65252"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(all_train_texts, train_X, train_Y, all_test_texts, test_X, test_Y, \"lgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9bb9bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 3M words\n",
      "Number of words:  187892\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread:  195786 lr:  0.000000 avg.loss:  0.239153 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(all_train_texts, train_X, train_Y, all_test_texts, test_X, test_Y, \"normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "690150e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(all_train_texts, train_X, train_Y, all_test_texts, test_X, test_Y, \"knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ad1712",
   "metadata": {},
   "source": [
    "# LowerCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d1526d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8859260771459267"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "train_texts = [sentence.lower() for sentence in all_train_texts]\n",
    "test_texts = [sentence.lower() for sentence in all_test_texts]\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=True)\n",
    "train_X = vectorizer.fit_transform(train_texts)\n",
    "test_X = vectorizer.transform(test_texts)\n",
    "\n",
    "data_quality(vectorizer, train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23efa947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and rent a good horror movie. it\\'s like the writer had never seen a horror movie before and didn\\'t realize every single thing he wrote was clichéd and hackneyed and has been parodied to perfection in movies like \"scream\" and \"scary movie\".<br /><br />in between the scary bits is the most banal and boring dialog ever written. stupid \"we\\'re going to the prom\" junk. i wanted to claw my ears off. honestly, \"the hills\" has better dialog.<br /><br />there really was no need to make this movie. leading lady is uninteresting and i kept thinking \"her? really? guy is obsessed with her? really?\" <br /><br />all the characters act in stupid ways, including the police. (cover the place in teams of 2! front and back! not one sleepy cop sitting in his car with the window rolled down just waiting for his throat to be slashed.) <br /><br />the serial killer just swans about murdering everyone he wants without the least bit of problem. no resistance from victims (or doors). nobody has any protection or the least idea of fighting back (or flipping the security lock on the hotel room door). the people are like mentally disabled sheep.<br /><br />by the by, if you\\'re a gore fan, you\\'ll be disappointed too. all the killing is kept offscreen and is -- ahem -- tastefully done. (so boo hoo for you!) <br /><br />none of the killings is the least bit interesting. most of the time they\\'ve already happened by the time we find out.<br /><br />the only cliché missing was the cat that always pops out in this kind of movies. \"oh kitty! you scared me! i thought you were the killer -- aiieeee!\" <br /><br />and then at the end when it\\'s time for the killer to die -- well, let\\'s just say it\\'s the easiest and most obvious choice. snore.<br /><br />the audience was jeering and talking back to the screen throughout. it was too dumb to believe and not really scary enough. don\\'t encourage this kind of lazy film-making.<br /><br />(oh, and by the way -- no crowning of a prom king or queen. no tiara. no bucket of blood.) <br /><br />so save your money and rent \"carrie\" or \"friday the 13th\" or \"halloween\" or \"scream\" or \"scary movie\" (any of them) to get a good scare with some original twists.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03f71775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64124"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"nb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e610e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51444"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a32c79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.364107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 31942\n",
      "[LightGBM] [Info] Number of data points in the train set: 13500, number of used features: 8363\n",
      "[LightGBM] [Info] Start training from score -2.602690\n",
      "[LightGBM] [Info] Start training from score -0.076961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.65992"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"lgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f16e94ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 3M words\n",
      "Number of words:  169944\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread:  196580 lr:  0.000000 avg.loss:  0.217056 ETA:   0h 0m 0s 15.6% words/sec/thread:  198862 lr:  0.084394 avg.loss:  0.317472 ETA:   0h 0m22s 60.3% words/sec/thread:  197447 lr:  0.039683 avg.loss:  0.152661 ETA:   0h 0m10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"lower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88e0c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d925c7",
   "metadata": {},
   "source": [
    "# Stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecff5f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13500/13500 [01:28<00:00, 152.87it/s]\n",
      "100%|██████████| 25000/25000 [02:39<00:00, 156.60it/s]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def stem_sentences(sentences: str) -> str:\n",
    "    def stem_sentence(sentence):\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        return \" \".join(\n",
    "            porter.stem(word, to_lowercase=False) for word in words\n",
    "        )\n",
    "    return [stem_sentence(sentence) for sentence in tqdm(sentences)]\n",
    "\n",
    "train_texts, test_texts = stem_sentences(all_train_texts), stem_sentences(all_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1952c68-1a9c-4950-b84d-99122c2eff61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"and rent a GOOD horror movi . It 's like the writer had never seen a horror movi befor and did n't realiz everi singl thing he wrote wa clichéd and hackney and ha been parodi to perfect in movi like `` Scream '' and `` Scari Movi '' . < br / > < br / > In between the scari bit is the most BANAL and BORING dialog ever written . Stupid `` we 're go to the prom '' junk . I want to claw my ear off . Honestli , `` The Hill '' ha better dialog. < br / > < br / > There realli wa no need to make thi movi . Lead ladi is uninterest and I kept think `` Her ? Realli ? Guy is obsess with her ? Realli ? '' < br / > < br / > All the charact act in stupid way , includ the polic . ( Cover the place in team of 2 ! Front and back ! Not one sleepi cop sit in hi car with the window roll down just wait for hi throat to be slash . ) < br / > < br / > The serial killer just swan about murder everyon he want without the least bit of problem . No resist from victim ( or door ) . Nobodi ha ani protect or the least idea of fight back ( or flip the secur lock on the hotel room door ) . The peopl are like mental disabl sheep. < br / > < br / > By the by , if you 're a gore fan , you 'll be disappoint too . All the kill is kept offscreen and is -- ahem -- tast done . ( So boo hoo for you ! ) < br / > < br / > None of the kill is the least bit interest . Most of the time they 've alreadi happen by the time we find out. < br / > < br / > The onli cliché miss wa the cat that alway pop out in thi kind of movi . `` Oh kitti ! You scare me ! I thought you were the killer -- AIIEEEE ! '' < br / > < br / > And then at the end when it 's time for the killer to die -- well , let 's just say it 's the easiest and most obviou choic . Snore. < br / > < br / > The audienc wa jeer and talk back to the screen throughout . It wa too dumb to believ and not realli scari enough . Do n't encourag thi kind of lazi film-making. < br / > < br / > ( Oh , and by the way -- no crown of a prom king or queen . No tiara . No bucket of blood . ) < br / > < br / > So save your money and rent `` Carri '' or `` Friday the 13th '' or `` Halloween '' or `` Scream '' or `` Scari Movi '' ( ani of them ) to get a good scare with some origin twist .\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0ae3f1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.061223947072388"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=True)\n",
    "train_X = vectorizer.fit_transform(train_texts)\n",
    "test_X = vectorizer.transform(test_texts)\n",
    "\n",
    "data_quality(vectorizer, train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc7fa80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66008"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"nb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "faa9ffcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51784"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3db40450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.318744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 27324\n",
      "[LightGBM] [Info] Number of data points in the train set: 13500, number of used features: 6611\n",
      "[LightGBM] [Info] Start training from score -2.602690\n",
      "[LightGBM] [Info] Start training from score -0.076961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.65352"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"lgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5283db5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 3M words\n",
      "Number of words:  73194\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread:  212852 lr:  0.000000 avg.loss:  0.162846 ETA:   0h 0m 0s% words/sec/thread:  213267 lr:  0.049754 avg.loss:  0.148585 ETA:   0h 0m15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"stem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce88e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edb421f",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c29a8016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4d4e4f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13500/13500 [00:46<00:00, 290.53it/s]\n",
      "100%|██████████| 25000/25000 [01:21<00:00, 305.72it/s]\n"
     ]
    }
   ],
   "source": [
    "def lemma_sentences(sentences: str) -> str:\n",
    "    def lemma_sentence(sentence):\n",
    "        return \" \".join(\n",
    "            wordnet_lemmatizer.lemmatize(word) for word in nltk.word_tokenize(sentence)\n",
    "        )\n",
    "    return [lemma_sentence(sentence) for sentence in tqdm(sentences)]\n",
    "\n",
    "train_texts, test_texts = lemma_sentences(all_train_texts), lemma_sentences(all_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c2287bd-4e5e-4b18-a98c-4700d097f26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"and rent a GOOD horror movie . It 's like the writer had never seen a horror movie before and did n't realize every single thing he wrote wa clichéd and hackneyed and ha been parodied to perfection in movie like `` Scream '' and `` Scary Movie '' . < br / > < br / > In between the scary bit is the most BANAL and BORING dialog ever written . Stupid `` we 're going to the prom '' junk . I wanted to claw my ear off . Honestly , `` The Hills '' ha better dialog. < br / > < br / > There really wa no need to make this movie . Leading lady is uninteresting and I kept thinking `` Her ? Really ? Guy is obsessed with her ? Really ? '' < br / > < br / > All the character act in stupid way , including the police . ( Cover the place in team of 2 ! Front and back ! Not one sleepy cop sitting in his car with the window rolled down just waiting for his throat to be slashed . ) < br / > < br / > The serial killer just swan about murdering everyone he want without the least bit of problem . No resistance from victim ( or door ) . Nobody ha any protection or the least idea of fighting back ( or flipping the security lock on the hotel room door ) . The people are like mentally disabled sheep. < br / > < br / > By the by , if you 're a gore fan , you 'll be disappointed too . All the killing is kept offscreen and is -- ahem -- tastefully done . ( So boo hoo for you ! ) < br / > < br / > None of the killing is the least bit interesting . Most of the time they 've already happened by the time we find out. < br / > < br / > The only cliché missing wa the cat that always pop out in this kind of movie . `` Oh kitty ! You scared me ! I thought you were the killer -- AIIEEEE ! '' < br / > < br / > And then at the end when it 's time for the killer to die -- well , let 's just say it 's the easiest and most obvious choice . Snore. < br / > < br / > The audience wa jeering and talking back to the screen throughout . It wa too dumb to believe and not really scary enough . Do n't encourage this kind of lazy film-making. < br / > < br / > ( Oh , and by the way -- no crowning of a prom king or queen . No tiara . No bucket of blood . ) < br / > < br / > So save your money and rent `` Carrie '' or `` Friday the 13th '' or `` Halloween '' or `` Scream '' or `` Scary Movie '' ( any of them ) to get a good scare with some original twist .\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d76841b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9242641955812305"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=True)\n",
    "train_X = vectorizer.fit_transform(train_texts)\n",
    "test_X = vectorizer.transform(test_texts)\n",
    "\n",
    "data_quality(vectorizer, train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e20e203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64548"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"nb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9db572a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5192"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b18d0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.911036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 30154\n",
      "[LightGBM] [Info] Number of data points in the train set: 13500, number of used features: 7744\n",
      "[LightGBM] [Info] Start training from score -2.602690\n",
      "[LightGBM] [Info] Start training from score -0.076961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.65684"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"lgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca17e360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 3M words\n",
      "Number of words:  88272\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread:  210750 lr:  0.000000 avg.loss:  0.181554 ETA:   0h 0m 0s 50.7% words/sec/thread:  211966 lr:  0.049316 avg.loss:  0.157118 ETA:   0h 0m15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"lemma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6a25f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611f5f7d",
   "metadata": {},
   "source": [
    "# Remove Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ac54ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13500/13500 [00:34<00:00, 396.99it/s]\n",
      "100%|██████████| 25000/25000 [01:02<00:00, 402.56it/s]\n"
     ]
    }
   ],
   "source": [
    "def remove_stop_sentences(sentences: str) -> str:\n",
    "    def remove_stop_sentence(sentence):\n",
    "        return \" \".join(\n",
    "            word for word in nltk.word_tokenize(sentence) if word not in stopWords\n",
    "        )\n",
    "    return [remove_stop_sentence(sentence) for sentence in tqdm(sentences)]\n",
    "\n",
    "train_texts, test_texts = remove_stop_sentences(all_train_texts), remove_stop_sentences(all_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9937aac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 168.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"rent GOOD horror movie . It 's like writer never seen horror movie n't realize every single thing wrote clichéd hackneyed parodied perfection movies like `` Scream '' `` Scary Movie '' . < br / > < br / > In scary bits BANAL BORING dialog ever written . Stupid `` 're going prom '' junk . I wanted claw ears . Honestly , `` The Hills '' better dialog. < br / > < br / > There really need make movie . Leading lady uninteresting I kept thinking `` Her ? Really ? Guy obsessed ? Really ? '' < br / > < br / > All characters act stupid ways , including police . ( Cover place teams 2 ! Front back ! Not one sleepy cop sitting car window rolled waiting throat slashed . ) < br / > < br / > The serial killer swans murdering everyone wants without least bit problem . No resistance victims ( doors ) . Nobody protection least idea fighting back ( flipping security lock hotel room door ) . The people like mentally disabled sheep. < br / > < br / > By , 're gore fan , 'll disappointed . All killing kept offscreen -- ahem -- tastefully done . ( So boo hoo ! ) < br / > < br / > None killings least bit interesting . Most time 've already happened time find out. < br / > < br / > The cliché missing cat always pops kind movies . `` Oh kitty ! You scared ! I thought killer -- AIIEEEE ! '' < br / > < br / > And end 's time killer die -- well , let 's say 's easiest obvious choice . Snore. < br / > < br / > The audience jeering talking back screen throughout . It dumb believe really scary enough . Do n't encourage kind lazy film-making. < br / > < br / > ( Oh , way -- crowning prom king queen . No tiara . No bucket blood . ) < br / > < br / > So save money rent `` Carrie '' `` Friday 13th '' `` Halloween '' `` Scream '' `` Scary Movie '' ( ) get good scare original twists .\"]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stop_sentences([all_train_texts[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "136ea990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.854712551428751"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=True)\n",
    "train_X = vectorizer.fit_transform(train_texts)\n",
    "test_X = vectorizer.transform(test_texts)\n",
    "\n",
    "data_quality(vectorizer, train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dbcf1d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62848"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"nb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb196a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5114"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e6930b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 3.363173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 30964\n",
      "[LightGBM] [Info] Number of data points in the train set: 13500, number of used features: 8345\n",
      "[LightGBM] [Info] Start training from score -2.602690\n",
      "[LightGBM] [Info] Start training from score -0.076961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.66568"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"lgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7238882b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 2M words\n",
      "Number of words:  93535\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread:  206976 lr:  0.000000 avg.loss:  0.195800 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"rem_stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c9b6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dde3447",
   "metadata": {},
   "source": [
    "# f_classify threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0d15e359",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13500/13500 [00:28<00:00, 473.49it/s]\n",
      "100%|██████████| 25000/25000 [00:52<00:00, 478.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.148735931797523"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=False)\n",
    "train_X = vectorizer.fit_transform(all_train_texts)\n",
    "test_X = vectorizer.transform(all_test_texts)\n",
    "\n",
    "from sklearn.feature_selection import f_classif\n",
    "F, pvalues_f = f_classif(train_X, train_Y)\n",
    "value_names = sorted(zip(vectorizer.get_feature_names(), F), key=lambda x: x[1], reverse=True)\n",
    "filter_names = [name for name, value in value_names[-int(len(value_names)*0.2):]]\n",
    "\n",
    "def remove_words_sentences(sentences: str, removed_words: set) -> str:\n",
    "    def remove_words_sentence(sentence):\n",
    "        return \" \".join(\n",
    "            word for word in nltk.word_tokenize(sentence) if word not in removed_words\n",
    "        )\n",
    "    return [remove_words_sentence(sentence) for sentence in tqdm(sentences)]\n",
    "\n",
    "train_texts, test_texts = remove_words_sentences(all_train_texts, set(filter_names)), remove_words_sentences(all_test_texts, set(filter_names))\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=False)\n",
    "train_X = vectorizer.fit_transform(train_texts)\n",
    "test_X = vectorizer.transform(test_texts)\n",
    "\n",
    "data_quality(vectorizer, train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66b50d7a-687b-42f7-b9cd-e1cd90ccc797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"and rent a GOOD horror movie . It 's like the writer had never a horror movie and n't realize every single thing he wrote was clichéd and hackneyed and has been parodied to perfection in movies like `` Scream '' and `` Scary Movie '' . < br / > < br / > In between the scary bits is the most BANAL and BORING dialog ever written . Stupid `` 're going to the prom '' junk . I wanted to claw my ears off . Honestly , `` Hills '' has better dialog. < br / > < br / > There really was no need to make this movie . Leading is uninteresting and I kept thinking `` Her ? Really ? Guy is obsessed with ? Really ? '' < br / > < br / > All the characters act in stupid ways , including the police . ( Cover the in teams of 2 ! Front and back ! Not one sleepy sitting in his car with the window rolled down just waiting for his throat to be slashed . ) < br / > < br / > serial killer just swans about murdering everyone he wants without the least bit of problem . No resistance from victims ( or ) . Nobody has any protection or the least idea of fighting back ( or the security on the hotel room door ) . people are like disabled sheep. < br / > < br / > the by , if 're a gore fan , 'll be disappointed too . All the killing is kept offscreen and is -- ahem -- tastefully done . ( So boo hoo for ! ) < br / > < br / > None of the killings is the least bit interesting . of the time they 've already happened by the time find out. < br / > < br / > only cliché missing was the cat that always pops out in this kind of movies . `` Oh kitty ! You scared me ! I thought were the killer -- AIIEEEE ! '' < br / > < br / > And then at the when it 's time for the killer to die -- well , let 's just say it 's the and most obvious choice . Snore. < br / > < br / > audience was jeering and talking back to the screen throughout . It was too dumb to believe and not really scary enough . Do n't encourage this kind of lazy film-making. < br / > < br / > ( Oh , and by the -- no crowning of a prom king or queen . No tiara . No of blood . ) < br / > < br / > So save your money and rent `` Carrie '' or `` Friday the 13th '' or `` Halloween '' or `` Scream '' or `` Scary Movie '' ( any of them ) to get a good scare with some original twists .\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "113227f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62852"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"nb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ba88a336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51784"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7da77a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 3.010197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 29387\n",
      "[LightGBM] [Info] Number of data points in the train set: 13500, number of used features: 7818\n",
      "[LightGBM] [Info] Start training from score -2.602690\n",
      "[LightGBM] [Info] Start training from score -0.076961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.65548"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"lgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38d48fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 3M words\n",
      "Number of words:  80452\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread:  212769 lr:  0.000000 avg.loss:  0.138190 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"remove_f_thre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08ca1592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a9b233",
   "metadata": {},
   "source": [
    "# CHI2_threshold\n",
    "## Chi40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7eaa4357",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(lowercase=False)\n",
    "train_X = vectorizer.fit_transform(all_train_texts)\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "F, pvalues_f = chi2(train_X, train_Y)\n",
    "value_names = sorted(zip(vectorizer.get_feature_names(), F), key=lambda x: x[1], reverse=True)\n",
    "filter_names = [name for name, value in value_names[-int(len(value_names)*0.4):]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "989e2c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 155.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"and rent a GOOD horror movie . It 's like the writer had never a horror movie and n't realize every single thing he wrote was clichéd and hackneyed and has been parodied to perfection in movies like `` Scream '' and `` Scary Movie '' . < br / > < br / > In between the scary bits is the most BANAL and BORING dialog ever written . Stupid `` 're going to the prom '' junk . I wanted to claw my ears off . Honestly , `` Hills '' has better dialog. < br / > < br / > There really was no need to make this movie . Leading is uninteresting and I kept thinking `` Her ? Really ? Guy is obsessed with her ? Really ? '' < br / > < br / > All the characters act in stupid ways , including the police . ( Cover the in teams of 2 ! Front and back ! Not one sleepy cop sitting in his car with the window rolled down just waiting for his throat to be slashed . ) < br / > < br / > serial killer just swans about murdering everyone he wants without the least bit of problem . No resistance from victims ( or ) . Nobody has any protection or the least idea of fighting back ( or the security on the hotel room door ) . people are like disabled sheep. < br / > < br / > the by , if you 're a gore fan , you 'll be disappointed too . All the killing is kept offscreen and is -- ahem -- tastefully done . ( So boo hoo for you ! ) < br / > < br / > None of the killings is the least bit interesting . of the time they 've already happened by the time find out. < br / > < br / > only cliché missing was the cat that always pops out in this kind of movies . `` Oh kitty ! You scared me ! I thought you were the killer -- AIIEEEE ! '' < br / > < br / > And then at the when it 's time for the killer to die -- well , let 's just say it 's the and most obvious choice . Snore. < br / > < br / > audience was jeering and talking back to the screen throughout . It was too dumb to believe and not really scary enough . Do n't encourage this kind of lazy film-making. < br / > < br / > ( Oh , and by the -- no crowning of a prom king or queen . No tiara . No of blood . ) < br / > < br / > So save your money and rent `` Carrie '' or `` Friday the 13th '' or `` Halloween '' or `` Scream '' or `` Scary Movie '' ( any of them ) to get a good scare with some original twists .\"]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_words_sentences([all_train_texts[0]], set(filter_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49c2c055",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13500/13500 [00:28<00:00, 473.94it/s]\n",
      "100%|██████████| 25000/25000 [00:52<00:00, 475.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.7622077718188245"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts, test_texts = remove_words_sentences(all_train_texts, set(filter_names)), remove_words_sentences(all_test_texts, set(filter_names))\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=False)\n",
    "train_X = vectorizer.fit_transform(train_texts)\n",
    "test_X = vectorizer.transform(test_texts)\n",
    "\n",
    "data_quality(vectorizer, train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1583b38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3f058549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62912"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"nb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d953e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5176"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f7af6970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.827376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 29534\n",
      "[LightGBM] [Info] Number of data points in the train set: 13500, number of used features: 7808\n",
      "[LightGBM] [Info] Start training from score -2.602690\n",
      "[LightGBM] [Info] Start training from score -0.076961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6522"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"lgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9814a0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 3M words\n",
      "Number of words:  67115\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread:  211138 lr:  0.000000 avg.loss:  0.253441 ETA:   0h 0m 0s 58.4% words/sec/thread:  211215 lr:  0.041608 avg.loss:  0.137040 ETA:   0h 0m11s 211170 lr:  0.016489 avg.loss:  0.267469 ETA:   0h 0m 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"chi2_04\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2ecc9ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae37bf1",
   "metadata": {},
   "source": [
    "# CHI2_02\n",
    "## Chi20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d545864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "54662ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.215442112871815"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=False)\n",
    "train_X = vectorizer.fit_transform(all_train_texts)\n",
    "test_X = vectorizer.transform(all_test_texts)\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "F, pvalues_f = chi2(train_X, train_Y)\n",
    "value_names = sorted(zip(vectorizer.get_feature_names(), F), key=lambda x: x[1], reverse=True)\n",
    "filter_names = [name for name, value in value_names[-int(len(value_names)*0.2):]]\n",
    "\n",
    "data_quality(vectorizer, train_X, train_Y, 1, set(filter_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "32c8f600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13500/13500 [00:28<00:00, 472.91it/s]\n",
      "100%|██████████| 25000/25000 [00:52<00:00, 479.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.1531971982226263"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts, test_texts = remove_words_sentences(all_train_texts, set(filter_names)), remove_words_sentences(all_test_texts, set(filter_names))\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=False)\n",
    "train_X = vectorizer.fit_transform(train_texts)\n",
    "test_X = vectorizer.transform(test_texts)\n",
    "data_quality(vectorizer, train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d900d1e-f0bc-41ad-ac14-fc4b426dc680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"and rent a GOOD horror movie . It 's like the writer had never a horror movie and n't realize every single thing he wrote was clichéd and hackneyed and has been parodied to perfection in movies like `` Scream '' and `` Scary Movie '' . < br / > < br / > In between the scary bits is the most BANAL and BORING dialog ever written . Stupid `` 're going to the prom '' junk . I wanted to claw my ears off . Honestly , `` Hills '' has better dialog. < br / > < br / > There really was no need to make this movie . Leading is uninteresting and I kept thinking `` Her ? Really ? Guy is obsessed with her ? Really ? '' < br / > < br / > All the characters act in stupid ways , including the police . ( Cover the in teams of 2 ! Front and back ! Not one sleepy cop sitting in his car with the window rolled down just waiting for his throat to be slashed . ) < br / > < br / > serial killer just swans about murdering everyone he wants without the least bit of problem . No resistance from victims ( or ) . Nobody has any protection or the least idea of fighting back ( or the security on the hotel room door ) . people are like disabled sheep. < br / > < br / > the by , if you 're a gore fan , you 'll be disappointed too . All the killing is kept offscreen and is -- ahem -- tastefully done . ( So boo hoo for you ! ) < br / > < br / > None of the killings is the least bit interesting . of the time they 've already happened by the time find out. < br / > < br / > only cliché missing was the cat that always pops out in this kind of movies . `` Oh kitty ! You scared me ! I thought you were the killer -- AIIEEEE ! '' < br / > < br / > And then at the when it 's time for the killer to die -- well , let 's just say it 's the and most obvious choice . Snore. < br / > < br / > audience was jeering and talking back to the screen throughout . It was too dumb to believe and not really scary enough . Do n't encourage this kind of lazy film-making. < br / > < br / > ( Oh , and by the -- no crowning of a prom king or queen . No tiara . No of blood . ) < br / > < br / > So save your money and rent `` Carrie '' or `` Friday the 13th '' or `` Halloween '' or `` Scream '' or `` Scary Movie '' ( any of them ) to get a good scare with some original twists .\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d0cc27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62896"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"nb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3475628b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52032"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "69800f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.902493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 29921\n",
      "[LightGBM] [Info] Number of data points in the train set: 13500, number of used features: 7926\n",
      "[LightGBM] [Info] Start training from score -2.602690\n",
      "[LightGBM] [Info] Start training from score -0.076961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.65396"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"lgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9121bf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 3M words\n",
      "Number of words:  80466\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread:  211590 lr:  0.000000 avg.loss:  0.200390 ETA:   0h 0m 0ss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49996"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"chi2_02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "08a269f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(train_texts, train_X, train_Y, test_texts, test_X, test_Y, \"knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f8f5bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# neigh = KNeighborsClassifier(n_neighbors=3)  \n",
    "# neigh.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06fd364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = neigh.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750eb6f2-a205-4cae-9091-dfe56a5acf53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e6f3d7-bef3-406c-aab9-dce2ea176bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e03bea-379b-4c8f-9520-d1c2e3e45591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c63b7b314f0f8feaa4096db9046dfe18edc0516c1ae347727067c69fc71ca872"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
